{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 50 Startups:\n",
    "We will have to create a model to find in which comapny a capital venture should invest in.\n",
    "It has five columns R&D Spend,Administration,Marketing spend,State and Profit. So profit will be our Dependent variable and all other varibales will be independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "\n",
    "An independent variable is the variable that is changed or controlled in a scientific experiment to test the effects on the dependent variable.\n",
    "\n",
    "A dependent variable is the variable being tested and measured in a scientific experiment.\n",
    "\n",
    "The dependent variable is 'dependent' on the independent variable. As the experimenter changes the independent variable, the effect on the dependent variable is observed and recorded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple linear regression:\n",
    "\n",
    "similer to simple linear regression in which we had limited combination of variables. In multiple linear regression we have multiple combination of variables as shown below-\n",
    "                    \n",
    "                 y = b0 + b1*X1 + b2*X2  ... +bn*Xn\n",
    "                     y = Dependent variable\n",
    "                     x1,x2,xn = Independent variables\n",
    "                     b0 = constant\n",
    "                     b1,b2,b3 = coefficients.\n",
    "With respect to our model our equation will become:\n",
    "                \n",
    "           y   =  b0      + b1*x1           + b2*x2         + b3*x3         + b4*x4\n",
    "     Profit  Constant  R&D_Spend(dollar)  Admin(dollar)   Marketing(dollar)   State(name)\n",
    "Assumptions of linear Regression-\n",
    "1.Linearity\n",
    "2.homoscedasticity\n",
    "3.Multivariate normality\n",
    "4.Independence of errors\n",
    "5.Lack of multicollearity\n",
    "\n",
    "Before building a linear regression model we need to check those assumtions are true.\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since our 4th variable is categorical variable we need to change it by dummy variables.\n",
    "Our State variable will look like this after changing it to dummy variable-\n",
    "                    \n",
    "                    New York | California\n",
    "                           0 |1\n",
    "                           1 |0\n",
    "                           1 |0\n",
    "                           0 |1\n",
    "                           \n",
    "  our 4th varibale will become  b4*D1\n",
    "                                  b4 = coficient\n",
    "                                  D1 = dummmy variable\n",
    "                              \n",
    "  If we see our var again we see that we dnt require California  column as 1 in new york column states new yorn and 0 will represt califrnia.\n",
    "  \n",
    "  But we have another issue here that in case of califrnia the whole variable will become      0. But actually it is not a problem as how linear equation works is it will take that 0 as a default value in that constant b0 in main equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy variable trap -\n",
    "Why did in our last step we ignored california.We could simply split it into two variableslike - \n",
    "                \n",
    "             y = b0 + b1*x1 + b2*x2 + b3*x3 + b4*D1 + b5*D2\n",
    "                                              dumm1   dummy2\n",
    "But we can not have constant and both the var in same equation (to find).\n",
    "So always omit one dummy variable of total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P value :\n",
    "P value is a statistical measure that helps scientists determine whether or not their hypotheses are correct. P values are used to determine whether the results of their experiment are within the normal range of values for the events being observed. Usually, if the P value of a data set is below a certain pre-determined amount (like, for instance, 0.05), scientists will reject the \"null hypothesis\" of their experiment - in other words, they'll rule out the hypothesis that the variables of their experiment had no meaningful effect on the results.\n",
    "\n",
    "                https://www.wikihow.com/Calculate-P-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we have multple independent variable we need to decide which one to keep and which one to remove as these var may not be affecting our dependent variable.So we need not to keep them with us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 methods to build a model:\n",
    "    -All-in\n",
    "    -Backward elimination\n",
    "    -Foreward Selection\n",
    "    -Bidirectional Elimination\n",
    "    -Score Comparision\n",
    "\n",
    "Bidirectional Elimination are also called Step wise regression.\n",
    "\n",
    "All-in:\n",
    "In these we keep all our variables with us because we have prior knowledge or to prepare for backward elimination\n",
    "\n",
    "Backward elimination:\n",
    "Step-1 - select a significent level to stay in model(e.g.SL = 0.05)\n",
    "Step-2 - Fit the model with all the possible predictors.\n",
    "Step-3 - Consider the predictors with the highest  P-value. If P > SL, go to step 4. otherwise go to FIN\n",
    "Step-4 - Remove the predictors.\n",
    "Step-5 - Fit model with out this variable.\n",
    "Step-6 - Your model is ready.\n",
    "Keep repeating step 3 to 4 untill you reach a stage where all variables have p value less then significence level.\n",
    "\n",
    "Foreward selection:\n",
    "Step-1 - select a significent level to enter the model(e.g.SL = 0.05)\n",
    "Step-2 - We take all the dependent variables and we create a regression model with every single independent var. Out of all the models we select the one with lowest p-value.\n",
    "Step-3 - keep this variable and creta a model one with one extra predictor added to the one you already have.\n",
    "Step-4 - Consider the predictor with the lowest P-value. If P<SL go to step 3 else go to FIN.\n",
    "Step-5 -Keep the previous model.\n",
    "\n",
    "\n",
    "Bidirectional Elimination:\n",
    "Step-1 - select a significence level to enter and stay in the model.e.g.SLENTER = 0.05,SLSTAY = 0.05.\n",
    "Step-2 - Perform the next step of foreward selection (new variable must have: P < SLENTER to enter)\n",
    "Step-3 - Perform all steps of the Backward Elimination(old variable must have P < SLSTAY)\n",
    "Step-4 - No new variables can enter and no old variables can exit. \n",
    "Step-5 - The model is ready.\n",
    "\n",
    "All Possible model:\n",
    "Step-1 - Select a criterion of goodness of fit.\n",
    "Step-2 - Construct all possible regression models 2^N-1 total combinations.\n",
    "Step-3 - Select the one with the best criterion.\n",
    "Step-4 - Your model is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"/home/vaibhav/AIGit/MultipleLinearRegression/50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_set.iloc[:,0:4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data_set.iloc[:,4:5].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 1.0000000e+00 1.6534920e+05 1.3689780e+05\n",
      "  4.7178410e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6259770e+05 1.5137759e+05\n",
      "  4.4389853e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.5344151e+05 1.0114555e+05\n",
      "  4.0793454e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.4437241e+05 1.1867185e+05\n",
      "  3.8319962e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.4210734e+05 9.1391770e+04\n",
      "  3.6616842e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.3187690e+05 9.9814710e+04\n",
      "  3.6286136e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3461546e+05 1.4719887e+05\n",
      "  1.2771682e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3029813e+05 1.4553006e+05\n",
      "  3.2387668e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.2054252e+05 1.4871895e+05\n",
      "  3.1161329e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2333488e+05 1.0867917e+05\n",
      "  3.0498162e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.0191308e+05 1.1059411e+05\n",
      "  2.2916095e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0067196e+05 9.1790610e+04\n",
      "  2.4974455e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.3863750e+04 1.2732038e+05\n",
      "  2.4983944e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 9.1992390e+04 1.3549507e+05\n",
      "  2.5266493e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.1994324e+05 1.5654742e+05\n",
      "  2.5651292e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.1452361e+05 1.2261684e+05\n",
      "  2.6177623e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.8013110e+04 1.2159755e+05\n",
      "  2.6434606e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 9.4657160e+04 1.4507758e+05\n",
      "  2.8257431e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 9.1749160e+04 1.1417579e+05\n",
      "  2.9491957e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 8.6419700e+04 1.5351411e+05\n",
      "  0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 7.6253860e+04 1.1386730e+05\n",
      "  2.9866447e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.8389470e+04 1.5377343e+05\n",
      "  2.9973729e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.3994560e+04 1.2278275e+05\n",
      "  3.0331926e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.7532530e+04 1.0575103e+05\n",
      "  3.0476873e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.7044010e+04 9.9281340e+04\n",
      "  1.4057481e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.4664710e+04 1.3955316e+05\n",
      "  1.3796262e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 7.5328870e+04 1.4413598e+05\n",
      "  1.3405007e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 7.2107600e+04 1.2786455e+05\n",
      "  3.5318381e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.6051520e+04 1.8264556e+05\n",
      "  1.1814820e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 6.5605480e+04 1.5303206e+05\n",
      "  1.0713838e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 6.1994480e+04 1.1564128e+05\n",
      "  9.1131240e+04]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 6.1136380e+04 1.5270192e+05\n",
      "  8.8218230e+04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 6.3408860e+04 1.2921961e+05\n",
      "  4.6085250e+04]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 5.5493950e+04 1.0305749e+05\n",
      "  2.1463481e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.6426070e+04 1.5769392e+05\n",
      "  2.1079767e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 4.6014020e+04 8.5047440e+04\n",
      "  2.0551764e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.8663760e+04 1.2705621e+05\n",
      "  2.0112682e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.4069950e+04 5.1283140e+04\n",
      "  1.9702942e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 2.0229590e+04 6.5947930e+04\n",
      "  1.8526510e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.8558510e+04 8.2982090e+04\n",
      "  1.7499930e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8754330e+04 1.1854605e+05\n",
      "  1.7279567e+05]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 2.7892920e+04 8.4710770e+04\n",
      "  1.6447071e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3640930e+04 9.6189630e+04\n",
      "  1.4800111e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.5505730e+04 1.2738230e+05\n",
      "  3.5534170e+04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2177740e+04 1.5480614e+05\n",
      "  2.8334720e+04]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0002300e+03 1.2415304e+05\n",
      "  1.9039300e+03]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 1.3154600e+03 1.1581621e+05\n",
      "  2.9711446e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3542692e+05\n",
      "  0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 5.4205000e+02 5.1743150e+04\n",
      "  0.0000000e+00]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1698380e+05\n",
      "  4.5173060e+04]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "labelencoder_x = LabelEncoder()\n",
    "X[:,3] = labelencoder_x.fit_transform(X[:,3])\n",
    "ct = ColumnTransformer([('encoder', OneHotEncoder(), [3])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X), dtype=np.float)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoiding the Dummy Variable trap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor = regressor.fit(x_train,y_train)\n",
    "Y_pred = regressor.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do it later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an optimal model using backward elimination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To add X0 = 1 in our matrix of features:\n",
    "    Normally in our equation we have:\n",
    "    \n",
    "            y   =  b0 + b1*x1 + b2*x2 + b3*x3+ b4*x4\n",
    "            here b0also has a independent var with it as x0 =1\n",
    "    while other models understand it but statsmodels.formula.api dont so we are adding a matrix of 1 in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(arr = np.ones((50,1)).astype(int),values = X,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_opt = X[:,[0,1,2,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = Y,exog = X_opt).fit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
